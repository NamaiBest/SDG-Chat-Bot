<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Locket - Voice Activated</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 30px;
            max-width: 700px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            margin: 0 auto;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }

        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            font-weight: bold;
        }

        .status.listening {
            background: #d1ecf1;
            color: #0c5460;
            border: 2px solid #bee5eb;
            animation: pulse 2s infinite;
        }

        .status.recording {
            background: #fff3cd;
            color: #856404;
            border: 2px solid #ffeeba;
        }

        .status.processing {
            background: #e2e3e5;
            color: #383d41;
            border: 2px solid #d6d8db;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .mic-indicator {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            margin: 30px auto;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 60px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
        }

        .mic-indicator.listening {
            animation: breathe 2s infinite;
        }

        .mic-indicator.recording {
            background: #dc3545;
            animation: recordPulse 1s infinite;
        }

        @keyframes breathe {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        @keyframes recordPulse {
            0%, 100% { transform: scale(1); box-shadow: 0 5px 15px rgba(220, 53, 69, 0.5); }
            50% { transform: scale(1.1); box-shadow: 0 10px 30px rgba(220, 53, 69, 0.8); }
        }

        .info {
            text-align: center;
            color: #666;
            margin: 20px 0;
            font-size: 14px;
        }

        .response-container {
            margin-top: 30px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            display: none;
        }

        .response-container.show {
            display: block;
        }

        .response-text {
            color: #333;
            margin-bottom: 15px;
            line-height: 1.6;
        }

        .back-link {
            display: inline-block;
            background: rgba(255, 255, 255, 0.95);
            color: #667eea;
            text-decoration: none;
            padding: 12px 24px;
            border-radius: 25px;
            font-weight: bold;
            position: fixed;
            top: 20px;
            left: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
            transition: all 0.3s ease;
            z-index: 1000;
        }

        .back-link:hover {
            background: white;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
        }

        /* Auto-read toggle */
        .auto-read-toggle {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.95);
            padding: 10px 15px;
            border-radius: 25px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
            z-index: 1000;
            display: flex;
            align-items: center;
            gap: 10px;
            font-size: 14px;
            font-weight: 500;
            color: #333;
        }

        .toggle-switch {
            position: relative;
            width: 48px;
            height: 26px;
            cursor: pointer;
        }

        .toggle-switch input {
            display: none;
        }

        .toggle-slider {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: #ccc;
            border-radius: 26px;
            transition: 0.3s;
        }

        .toggle-slider::before {
            content: '';
            position: absolute;
            width: 20px;
            height: 20px;
            left: 3px;
            bottom: 3px;
            background: white;
            border-radius: 50%;
            transition: 0.3s;
        }

        .toggle-switch input:checked + .toggle-slider {
            background: #667eea;
        }

        .toggle-switch input:checked + .toggle-slider::before {
            transform: translateX(22px);
        }

        .speaking-indicator {
            display: none;
            color: #667eea;
            font-size: 12px;
            animation: pulse 1.5s infinite;
        }

        .speaking-indicator.active {
            display: inline;
        }

        .debug-log {
            margin-top: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 10px;
            max-height: 200px;
            overflow-y: auto;
            font-size: 12px;
            font-family: monospace;
        }

        .debug-log div {
            margin: 5px 0;
            color: #666;
        }

        .video-preview-section {
            margin-top: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 10px;
            display: none;
        }

        .video-preview-section.show {
            display: block;
        }

        .video-toggle-btn {
            width: 100%;
            padding: 12px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            margin-bottom: 15px;
        }

        .video-toggle-btn:hover {
            opacity: 0.9;
        }

        .video-preview-container {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(100px, 1fr));
            gap: 10px;
            margin-top: 10px;
        }

        .video-frame {
            position: relative;
            border-radius: 8px;
            overflow: hidden;
            background: #e9ecef;
        }

        .video-frame img {
            width: 100%;
            height: auto;
            display: block;
        }

        .frame-label {
            position: absolute;
            top: 5px;
            left: 5px;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 10px;
            font-weight: bold;
        }

        .video-info {
            text-align: center;
            color: #666;
            margin-bottom: 10px;
            font-size: 14px;
        }

        /* Locket Connection Status */
        .locket-status {
            text-align: center;
            padding: 10px;
            border-radius: 8px;
            margin: 15px 0;
            font-size: 14px;
            font-weight: bold;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
        }

        .locket-status.online {
            background: #d4edda;
            color: #155724;
            border: 2px solid #c3e6cb;
        }

        .locket-status.offline {
            background: #f8d7da;
            color: #721c24;
            border: 2px solid #f5c6cb;
        }

        .locket-status .indicator {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: currentColor;
        }

        .locket-status.online .indicator {
            animation: blink 2s infinite;
        }

        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
    </style>
</head>
<body>
    <a href="javascript:history.back()" class="back-link">‚Üê Back to Chat</a>
    
    <!-- Auto-read toggle -->
    <div class="auto-read-toggle">
        <span>üîä Auto-read</span>
        <label class="toggle-switch">
            <input type="checkbox" id="autoReadToggle">
            <span class="toggle-slider"></span>
        </label>
        <span class="speaking-indicator" id="speakingIndicator">Speaking...</span>
    </div>
    
    <div class="container">
        <h1>üå± AI Locket</h1>
        
        <!-- Locket Connection Status -->
        <div class="locket-status offline" id="locketStatus">
            <span class="indicator"></span>
            <span id="locketStatusText">Locket Offline</span>
        </div>
        
        <div id="status" class="status listening">
            üé§ Listening for "Start Capture"
        </div>

        <div id="micIndicator" class="mic-indicator listening" onclick="toggleRecording()">
            üé§
        </div>

        <button id="debugBtn" class="debug-btn" onclick="toggleDebugMode()">
            üêõ
        </button>

        <div id="info" class="info">
            Say <strong>"Start Capture"</strong> to begin recording
        </div>

        <div id="responseContainer" class="response-container">
            <div id="responseText" class="response-text"></div>
            <audio id="audioPlayer" controls style="width: 100%; margin-top: 10px;"></audio>
        </div>

                <div class="debug-log" id="debugLog"></div>

        <!-- Video Preview Section -->
        <div style="margin-top: 20px;">
            <button class="video-toggle-btn" onclick="toggleVideoPreview()">
                üìπ Show Video Frames
            </button>
            <div class="video-preview-section" id="videoPreviewSection">
                <div class="video-info" id="videoInfo">
                    No frames captured yet
                </div>
                <div class="video-preview-container" id="videoPreviewContainer">
                </div>
            </div>
        </div>
    </div>

    <script>
        let recognition = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let sessionId = null;
        let username = null;
        let recordedTranscript = '';
        let capturedFrames = [];
        let currentSessionId = null;  // Store transcript during recording
        let isDebugMode = false;
        let debugStartTime = null;

        const status = document.getElementById('status');
        const micIndicator = document.getElementById('micIndicator');
        const info = document.getElementById('info');
        const responseContainer = document.getElementById('responseContainer');
        const responseText = document.getElementById('responseText');
        const audioPlayer = document.getElementById('audioPlayer');
        const debugLog = document.getElementById('debugLog');
        const autoReadToggle = document.getElementById('autoReadToggle');
        const speakingIndicator = document.getElementById('speakingIndicator');

        // Text-to-speech variables
        let speechSynthesis = window.speechSynthesis;
        let currentUtterance = null;

        // Get username from session storage
        username = sessionStorage.getItem('username');
        if (!username) {
            info.textContent = 'Please login first';
            setTimeout(() => window.location.href = '/', 2000);
        }

        // Load auto-read preference
        const savedAutoRead = localStorage.getItem('autoReadEnabled');
        if (savedAutoRead === 'true') {
            autoReadToggle.checked = true;
        }

        // Save auto-read preference
        autoReadToggle.addEventListener('change', () => {
            localStorage.setItem('autoReadEnabled', autoReadToggle.checked);
            if (!autoReadToggle.checked && currentUtterance) {
                speechSynthesis.cancel();
                speakingIndicator.classList.remove('active');
            }
        });

        // Format markdown text (bold, italic, etc.)
        function formatMarkdown(text) {
            if (!text) return '';
            return text
                .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')  // Bold
                .replace(/\*(.+?)\*/g, '<em>$1</em>')  // Italic
                .replace(/\n/g, '<br>')  // Line breaks
                .replace(/`(.+?)`/g, '<code>$1</code>');  // Inline code
        }

        // Text-to-speech function with natural voice
        function speakText(text) {
            if (!autoReadToggle.checked || !text) return;

            // Cancel any ongoing speech
            speechSynthesis.cancel();

            // Strip HTML tags for TTS
            const plainText = text.replace(/<[^>]*>/g, ' ').replace(/\s+/g, ' ').trim();
            
            currentUtterance = new SpeechSynthesisUtterance(plainText);
            
            // Configure voice for more natural sound
            const voices = speechSynthesis.getVoices();
            
            // Prefer high-quality female voices (more natural sounding)
            const preferredVoices = [
                'Samantha', 'Karen', 'Victoria', 'Zira',  // English voices
                'Google US English', 'Google UK English Female',
                'Microsoft Zira Desktop', 'Microsoft David Desktop',
                'Alex', 'Fiona'
            ];
            
            // Try to find a preferred voice
            let selectedVoice = voices.find(voice => 
                preferredVoices.some(pref => voice.name.includes(pref))
            );
            
            // Fallback to any English voice if preferred not found
            if (!selectedVoice) {
                selectedVoice = voices.find(voice => voice.lang.startsWith('en'));
            }
            
            if (selectedVoice) {
                currentUtterance.voice = selectedVoice;
            }
            
            // Configure speech parameters for natural sound
            currentUtterance.rate = 0.95;     // Slightly slower for clarity
            currentUtterance.pitch = 1.05;     // Slightly higher pitch
            currentUtterance.volume = 1.0;     // Full volume
            
            // Event listeners
            currentUtterance.onstart = () => {
                speakingIndicator.classList.add('active');
                log('üîä Speaking response...');
            };
            
            currentUtterance.onend = () => {
                speakingIndicator.classList.remove('active');
                log('‚úÖ Finished speaking');
            };
            
            currentUtterance.onerror = (e) => {
                speakingIndicator.classList.remove('active');
                log(`‚ö†Ô∏è Speech error: ${e.error}`);
            };
            
            // Speak the text
            speechSynthesis.speak(currentUtterance);
        }

        // Ensure voices are loaded
        if (speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = () => {
                // Voices are now loaded
            };
        }

        function log(message) {
            const div = document.createElement('div');
            div.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            debugLog.appendChild(div);
            debugLog.scrollTop = debugLog.scrollHeight;
            console.log(message);
        }

        // Initialize speech recognition
        function startVoiceActivation() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                log('‚ùå Speech recognition not supported');
                info.textContent = 'Speech recognition not supported in this browser';
                return;
            }

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                log('‚úÖ Voice activation started');
                status.textContent = 'üé§ Listening for "Start Capture"';
                status.className = 'status listening';
                micIndicator.className = 'mic-indicator listening';
            };

            recognition.onresult = (event) => {
                const transcript = Array.from(event.results)
                    .map(result => result[0].transcript)
                    .join(' ')
                    .toLowerCase();
                
                log(`Heard: "${transcript}"`);

                // Check for wake word to START recording
                if (transcript.includes('start capture') && !isRecording) {
                    log('üéØ Wake word detected!');
                    recordedTranscript = '';  // Reset transcript
                    startRecording();
                }
                
                // While recording, collect everything after "start capture"
                if (isRecording) {
                    // Extract text after "start capture" and before "stop capture"
                    let textToRecord = transcript;
                    if (textToRecord.includes('start capture')) {
                        textToRecord = textToRecord.split('start capture')[1] || '';
                    }
                    if (textToRecord.includes('stop capture')) {
                        textToRecord = textToRecord.split('stop capture')[0] || '';
                    }
                    recordedTranscript = textToRecord.trim();
                }
                
                // Check for command to STOP recording
                if (transcript.includes('stop capture') && isRecording) {
                    log('üõë Stop command detected!');
                    log(`üìù Captured text: "${recordedTranscript}"`);
                    stopRecording();
                }
            };

            recognition.onerror = (event) => {
                log(`‚ùå Recognition error: ${event.error}`);
                if (event.error === 'not-allowed') {
                    info.textContent = 'Microphone access denied. Please enable it in settings.';
                }
            };

            recognition.onend = () => {
                log('‚ö†Ô∏è Recognition ended, restarting...');
                if (!isRecording) {
                    setTimeout(() => recognition.start(), 1000);
                }
            };

            recognition.start();
        }

        function toggleRecording() {
            if (isRecording) {
                log('üõë Click to stop recording');
                stopRecording();
            } else {
                log('üéØ Click to start recording');
                recordedTranscript = '';  // Reset transcript
                startRecording();
            }
        }

        async function toggleDebugMode() {
            const debugBtn = document.getElementById('debugBtn');
            
            if (!isDebugMode) {
                // Start debug mode
                isDebugMode = true;
                debugStartTime = Date.now();
                debugBtn.classList.add('active');
                debugBtn.textContent = '‚èπÔ∏è';
                
                log('üêõ DEBUG MODE: Starting ESP32 capture...');
                status.textContent = 'üêõ Debug Mode Active - Capturing frames...';
                status.className = 'status recording';
                info.textContent = 'ESP32 is capturing frames. Click again to stop.';
                
                try {
                    // Tell server to start ESP32 recording in debug mode
                    const response = await fetch('/api/locket/debug-start', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ username })
                    });
                    
                    const data = await response.json();
                    if (data.success) {
                        sessionId = data.session_id;
                        log(`‚úÖ Debug session started: ${sessionId}`);
                    } else {
                        throw new Error(data.error || 'Failed to start debug mode');
                    }
                } catch (error) {
                    log(`‚ùå Debug mode error: ${error.message}`);
                    info.textContent = `Error: ${error.message}`;
                    isDebugMode = false;
                    debugBtn.classList.remove('active');
                    debugBtn.textContent = 'üêõ';
                }
            } else {
                // Stop debug mode
                isDebugMode = false;
                debugBtn.classList.remove('active');
                debugBtn.textContent = 'üêõ';
                
                const duration = ((Date.now() - debugStartTime) / 1000).toFixed(1);
                log(`üêõ DEBUG MODE: Stopped after ${duration}s`);
                status.textContent = 'üêõ Processing debug frames...';
                info.textContent = 'Analyzing captured frames with AI...';
                
                try {
                    // Tell server to stop and process with "what do you see" command
                    const response = await fetch('/api/locket/debug-stop', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ 
                            username,
                            session_id: sessionId,
                            query: 'what do you see'
                        })
                    });
                    
                    const data = await response.json();
                    if (data.success) {
                        log(`‚úÖ Debug complete: ${data.frames_captured} frames captured`);
                        
                        // Display AI response
                        if (data.response) {
                            document.getElementById('responseText').innerHTML = formatMarkdown(data.response);
                            responseContainer.classList.add('show');
                            
                            // Auto-read response if enabled
                            speakText(data.response);
                            
                            // Play audio if available
                            if (data.audio_url) {
                                const audioPlayer = document.getElementById('audioPlayer');
                                audioPlayer.src = data.audio_url;
                                audioPlayer.load();
                                audioPlayer.play().catch(e => log(`‚ö†Ô∏è Audio playback error: ${e.message}`));
                            }
                        }
                        
                        status.textContent = '‚úÖ Debug complete!';
                        status.className = 'status listening';
                        info.textContent = 'Debug mode ready. Click üêõ to capture again.';
                    } else {
                        throw new Error(data.error || 'Failed to process debug frames');
                    }
                } catch (error) {
                    log(`‚ùå Debug stop error: ${error.message}`);
                    info.textContent = `Error: ${error.message}`;
                    status.textContent = '‚ùå Debug failed';
                    status.className = 'status listening';
                }
            }
        }

        async function startRecording() {
            if (isRecording) return;
            isRecording = true;
            let recordingTimeout = null;

            log('üìπ Starting recording...');
            status.textContent = 'üî¥ Recording... Say "Stop Capture" or wait 10s';
            status.className = 'status recording';
            micIndicator.className = 'mic-indicator recording';
            info.textContent = 'Recording your question... Say "Stop Capture" to finish early';

            try {
                // Start phone audio recording
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    stream.getTracks().forEach(track => track.stop());
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await processRecording(audioBlob);
                };

                // Trigger ESP32 to start recording
                const response = await fetch('/api/locket/start-recording', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ username })
                });

                const data = await response.json();
                if (data.success) {
                    sessionId = data.session_id;
                    log(`‚úÖ ESP32 triggered, session: ${sessionId}`);
                    
                    // Start recording
                    mediaRecorder.start();
                    
                    // Restart recognition to listen for "stop capture"
                    if (recognition) {
                        setTimeout(() => recognition.start(), 500);
                    }

                    // Auto-stop after 30 seconds
                    recordingTimeout = setTimeout(() => {
                        if (mediaRecorder && mediaRecorder.state === 'recording') {
                            log('‚è±Ô∏è 30 seconds elapsed, stopping...');
                            stopRecording();
                        }
                    }, 30000);
                } else {
                    throw new Error(data.error || 'Failed to start ESP32');
                }
            } catch (error) {
                log(`‚ùå Error: ${error.message}`);
                info.textContent = `Error: ${error.message}`;
                isRecording = false;
                startVoiceActivation();
            }
        }

        function stopRecording() {
            if (!isRecording || !mediaRecorder) return;
            
            log('üõë Stopping recording...');
            
            // Stop the media recorder
            if (mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            
            // Stop listening for "stop capture"
            if (recognition) {
                recognition.stop();
            }
        }

        async function processRecording(audioBlob) {
            log('üì§ Uploading audio...');
            status.textContent = '‚è≥ Processing...';
            status.className = 'status processing';
            info.textContent = 'Sending to AI...';

            try {
                // Upload phone audio WITH transcript
                const formData = new FormData();
                formData.append('audio', audioBlob, 'audio.webm');
                formData.append('session_id', sessionId);
                formData.append('username', username);
                formData.append('transcript', recordedTranscript);  // Send the transcript!

                const response = await fetch('/api/locket/upload-audio', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                if (data.success) {
                    log('‚úÖ Processing complete!');
                    
                    // Display response
                    responseText.innerHTML = formatMarkdown(data.response || data.text || 'Response received');
                    responseContainer.classList.add('show');
                    
                    // Auto-read response if enabled
                    speakText(data.response || data.text);
                    
                    // Play audio response if available
                    if (data.audio_url) {
                        audioPlayer.src = data.audio_url;
                        audioPlayer.style.display = 'block';
                        audioPlayer.load();
                        audioPlayer.play().catch(e => log(`‚ö†Ô∏è Audio playback error: ${e.message}`));
                    }
                    
                    // Fetch and display video frames if session ID is available
                    if (sessionId) {
                        currentSessionId = sessionId;
                        await fetchSessionFrames(sessionId);
                    }
                    
                    info.textContent = 'Say "Start Capture" for next question';
                } else {
                    throw new Error(data.error || 'Processing failed');
                }
            } catch (error) {
                log(`‚ùå Upload error: ${error.message}`);
                info.textContent = `Error: ${error.message}`;
            }

            isRecording = false;
            status.textContent = 'üé§ Listening for "Start Capture"';
            status.className = 'status listening';
            micIndicator.className = 'mic-indicator listening';
            
            // Restart voice activation
            startVoiceActivation();
        }

        // Video preview functions
        function toggleVideoPreview() {
            const section = document.getElementById('videoPreviewSection');
            const btn = document.querySelector('.video-toggle-btn');
            
            if (section.classList.contains('show')) {
                section.classList.remove('show');
                btn.textContent = 'üìπ Show Video Frames';
            } else {
                section.classList.add('show');
                btn.textContent = 'üìπ Hide Video Frames';
            }
        }

        function displayVideoFrames(frames) {
            capturedFrames = frames;
            const container = document.getElementById('videoPreviewContainer');
            const info = document.getElementById('videoInfo');
            
            if (!frames || frames.length === 0) {
                info.textContent = 'No frames captured in this session';
                container.innerHTML = '';
                return;
            }
            
            info.textContent = `üì∏ ${frames.length} frame${frames.length > 1 ? 's' : ''} captured (~${(frames.length / 10).toFixed(1)} FPS)`;
            
            container.innerHTML = '';
            frames.forEach((frame, index) => {
                const frameDiv = document.createElement('div');
                frameDiv.className = 'video-frame';
                
                const img = document.createElement('img');
                // Extract base64 data from frame object
                const frameData = frame.data || frame;
                // If it already has the data URL prefix, use as-is; otherwise add it
                img.src = frameData.startsWith('data:') ? frameData : `data:image/jpeg;base64,${frameData}`;
                img.alt = `Frame ${index + 1}`;
                
                const label = document.createElement('div');
                label.className = 'frame-label';
                label.textContent = `#${index + 1}`;
                
                frameDiv.appendChild(img);
                frameDiv.appendChild(label);
                container.appendChild(frameDiv);
            });
            
            log(`üìπ Displayed ${frames.length} video frames`);
        }

        async function fetchSessionFrames(sessionId) {
            try {
                log(`üîç Fetching frames for session ${sessionId}...`);
                const response = await fetch(`/api/locket/session-frames/${sessionId}`);
                const data = await response.json();
                
                if (data.success && data.frames) {
                    displayVideoFrames(data.frames);
                } else {
                    log('‚ùå No frames available for this session');
                }
            } catch (error) {
                log(`‚ùå Error fetching frames: ${error.message}`);
            }
        }

        // Initialize on page load
        window.addEventListener('load', () => {
            log('üöÄ Initializing voice activation...');
            setTimeout(startVoiceActivation, 1000);
            
            // Start locket status check
            checkLocketStatus();
            setInterval(checkLocketStatus, 5000); // Check every 5 seconds
        });

        // Check if ESP32 locket is connected
        async function checkLocketStatus() {
            try {
                const response = await fetch(`/api/locket/status/${username}`);
                const data = await response.json();
                
                const statusElement = document.getElementById('locketStatus');
                const statusText = document.getElementById('locketStatusText');
                
                if (data.connected) {
                    statusElement.className = 'locket-status online';
                    statusText.textContent = '‚úÖ Locket Connected';
                } else {
                    statusElement.className = 'locket-status offline';
                    statusText.textContent = '‚ùå Locket Offline';
                }
            } catch (error) {
                console.error('Error checking locket status:', error);
                const statusElement = document.getElementById('locketStatus');
                const statusText = document.getElementById('locketStatusText');
                statusElement.className = 'locket-status offline';
                statusText.textContent = '‚ùå Locket Offline';
            }
        }
    </script>
</body>
</html>
